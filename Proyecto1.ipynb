{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d15c3f4-e6da-4c52-8e25-33f536d6087c",
   "metadata": {},
   "source": [
    "# Proyecto 1\n",
    "* Flavio Galán - 22386\n",
    "* Josue Say - 22801\n",
    "* Isabella Miralles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4322479-0609-4733-9ce1-979917dbfc86",
   "metadata": {},
   "source": [
    "## Descarga de los Datos\n",
    "\n",
    "Para descargar los datos se utiliza Selenium y Python, además se tiene un sistema de cacheo que funciona en base al archivo `links_cache.txt`. Si este archivo ya existe entonces no se realizará ninguna descarga de los datos. Los datos se guardan en varios archivos txt. Cada uno representa la columna del dataframe y todos los datos de esa columna. No se tienen en un formato JSON ni CSV sino que se guardan directamente en formato python para la facilidad de extracción usando el mismo lenguaje. Ya que estos son los datos sucios no hay ningún problema con guardarlos así, los datos limpios ya se guardarán en un formaton más estandarizado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83003afb",
   "metadata": {},
   "source": [
    "### Importaciones y configuración para el web scraping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ff481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "# import subprocess (se reemplazo con el uso de os para cualquier sistema operativo)\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b53dd8",
   "metadata": {},
   "source": [
    "### Configuración de rutas y archivo de caché"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106480f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_file_name = \"./cache/links_cache.txt\"\n",
    "df_cache_file = \"./cache/dataframe_cache.txt\"\n",
    "zip_dir = \"zips/\"\n",
    "files_dir = \"data/\"\n",
    "csv_file_path = \"./data/data_unified.csv\"\n",
    "reports = \"reportes/\"\n",
    "\n",
    "\n",
    "os.makedirs(\"cache\", exist_ok=True)\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"zips\", exist_ok=True)\n",
    "os.makedirs(\"reportes\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cc4f2d",
   "metadata": {},
   "source": [
    "### Inicialización de estructuras para almacenar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b65acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "codigo = []\n",
    "distrito = []\n",
    "departamento = []\n",
    "municipio = []\n",
    "establecimiento = []\n",
    "direccion = []\n",
    "telefono = []\n",
    "supervisor = []\n",
    "director = []\n",
    "nivel = []\n",
    "sector = []\n",
    "area = []\n",
    "status = []\n",
    "modalidad = []\n",
    "jornada = []\n",
    "plan = []\n",
    "departamental = []\n",
    "agggrArrays = [\n",
    "    codigo,\n",
    "    distrito,\n",
    "    departamento,\n",
    "    municipio,\n",
    "    establecimiento,\n",
    "    direccion,\n",
    "    telefono,\n",
    "    supervisor,\n",
    "    director,\n",
    "    nivel,\n",
    "    sector,\n",
    "    area,\n",
    "    status,\n",
    "    modalidad,\n",
    "    jornada,\n",
    "    plan,\n",
    "    departamental,\n",
    "]\n",
    "filenames = [\n",
    "    \"codigo\",\n",
    "    \"distrito\",\n",
    "    \"departamento\",\n",
    "    \"municipio\",\n",
    "    \"establecimiento\",\n",
    "    \"direccion\",\n",
    "    \"telefono\",\n",
    "    \"supervisor\",\n",
    "    \"director\",\n",
    "    \"nivel\",\n",
    "    \"sector\",\n",
    "    \"area\",\n",
    "    \"status\",\n",
    "    \"modalidad\",\n",
    "    \"jornada\",\n",
    "    \"plan\",\n",
    "    \"departamental\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09683fa0",
   "metadata": {},
   "source": [
    "### Carga de datos (web scrapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e95a071-af81-4d6c-8a94-160f46a335bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(cache_file_name):\n",
    "    with webdriver.Firefox() as driver:\n",
    "        driver.implicitly_wait(3)\n",
    "\n",
    "        driver.get(\"http://www.mineduc.gob.gt/BUSCAESTABLECIMIENTO_GE/\")\n",
    "        assert \"Búsqueda de centros\" in driver.title\n",
    "\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.XPATH, \"//*[@id='_ctl0_ContentPlaceHolder1_cmbDepartamento']\")\n",
    "            )\n",
    "        )\n",
    "        deptSelect = driver.find_element(\n",
    "            By.XPATH, \"//*[@id='_ctl0_ContentPlaceHolder1_cmbDepartamento']\"\n",
    "        )\n",
    "        deptSelect = Select(deptSelect)\n",
    "        depts = deptSelect.options\n",
    "        print(\"Getting depts\")\n",
    "        for idx in range(len(depts) - 1):\n",
    "            print(\"Selecting dept\", idx + 1)\n",
    "            deptSelect = driver.find_element(\n",
    "                By.XPATH, \"//*[@id='_ctl0_ContentPlaceHolder1_cmbDepartamento']\"\n",
    "            )\n",
    "            deptSelect = Select(deptSelect)\n",
    "            deptSelect.select_by_index(idx + 1)\n",
    "            print(\"Finding education level\")\n",
    "            levelSelect = driver.find_element(\n",
    "                By.XPATH, '//*[@id=\"_ctl0_ContentPlaceHolder1_cmbNivel\"]'\n",
    "            )\n",
    "            levelSelect = Select(levelSelect)\n",
    "            print(\"Selecting diversificado\")\n",
    "            levelSelect.select_by_value(\"46\")  # 46 es Diversificado\n",
    "            print(\"Finding search button\")\n",
    "            btn = driver.find_element(\n",
    "                By.XPATH, \"//*[@id='_ctl0_ContentPlaceHolder1_IbtnConsultar']\"\n",
    "            )\n",
    "            btn.click()\n",
    "            print(\"Clicking button\")\n",
    "\n",
    "            # Wait for results\n",
    "            print(\"Esperando por resultados\")\n",
    "            time.sleep(5)\n",
    "            print(\"Asumimos que se obtuvieron los resultados\")\n",
    "\n",
    "            table = driver.find_element(\n",
    "                By.XPATH, \"//*[@id='_ctl0_ContentPlaceHolder1_dgResultado']\"\n",
    "            )\n",
    "            rows = table.find_elements(By.XPATH, \".//tr\")\n",
    "            for rowIdx in range(\n",
    "                1, len(rows) - 1\n",
    "            ):  # La última fila siempre es una vacía\n",
    "                cells = rows[rowIdx].find_elements(By.XPATH, \".//td\")\n",
    "\n",
    "                for cellIdx in range(1, len(cells)):\n",
    "                    agggrArrays[cellIdx - 1].append(\n",
    "                        cells[cellIdx].get_attribute(\"textContent\")\n",
    "                    )\n",
    "\n",
    "            # print(\"Obtained following names\")\n",
    "            # print(establecimiento)\n",
    "            # exit(1)\n",
    "\n",
    "        print(\"Saving cache...\")\n",
    "        os.makedirs(zip_dir, exist_ok=True)\n",
    "        for idx in range(len(filenames)):\n",
    "            filename = filenames[idx]\n",
    "            data = agggrArrays[idx]\n",
    "\n",
    "            lines = [\"[\"]\n",
    "            for val in data:\n",
    "                line = f\"\\t'''{val}''',\\n\"\n",
    "                lines.append(line)\n",
    "            lines.append(\"]\")\n",
    "\n",
    "            with open(zip_dir + filename + \".txt\", \"w\") as file:\n",
    "                file.writelines(lines)\n",
    "\n",
    "        os.makedirs(os.path.dirname(cache_file_name), exist_ok=True)\n",
    "        with open(cache_file_name, \"w\") as file:\n",
    "            file.write(\"DELETE ME IF YOU WANT TO REDOWNLOAD DATA!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04de999e",
   "metadata": {},
   "source": [
    "### Carga de datos al DataFrame\n",
    "\n",
    "Este bloque verifica si existen los archivos de caché (`links_cache.txt` y `dataframe_cache.txt`). Si no hay caché, construye el `DataFrame` desde los datos extraídos y guarda un `.csv`. Si los cachés ya existen, carga directamente el `DataFrame` desde el archivo CSV, evitando repetir procesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c839c-a0e3-498e-9c62-457aed3d1bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDfCache(\n",
    "    filenames=None,\n",
    "    agggrArrays=None,\n",
    "    csvFile=csv_file_path,\n",
    "    dfCache=df_cache_file\n",
    "):\n",
    "    if os.path.exists(csvFile):\n",
    "        df = pd.read_csv(csvFile, encoding=\"utf-8-sig\")\n",
    "        print(\"DataFrame loaded from CSV:\")\n",
    "        print(df)\n",
    "\n",
    "        if not os.path.exists(dfCache):\n",
    "            with open(dfCache, \"w\") as f:\n",
    "                f.write(\"DataFrame cache created.\")\n",
    "    else:\n",
    "        df = pd.DataFrame(\n",
    "            {colName: colData for (colName, colData) in zip(filenames, agggrArrays)}\n",
    "        )\n",
    "        print(\"The resulting DataFrame is:\")\n",
    "        print(df)\n",
    "\n",
    "        df.to_csv(csvFile, index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "        with open(dfCache, \"w\") as f:\n",
    "            f.write(\"DataFrame cache created.\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ce6f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = loadDfCache(filenames, agggrArrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24409521",
   "metadata": {},
   "source": [
    "## Estructura del Conjunto de Datos Crudo\n",
    "\n",
    "En esta etapa se realiza un análisis exploratorio preliminar del conjunto de datos descargado, con el objetivo de conocer su estructura general. Se identifica la cantidad de filas y columnas, la presencia de datos duplicados, valores nulos por variable, y los tipos de datos registrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227cbc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataReport(df: pd.DataFrame, saveToFile: bool = True):\n",
    "    \"\"\"\n",
    "    Genera un resumen general del DataFrame con información básica.\n",
    "    \n",
    "    Parámetros:\n",
    "    - df: DataFrame de entrada.\n",
    "    - saveToFile: Si es True, guarda el reporte en 'reportes/reporte_general.txt'.\n",
    "\n",
    "    Retorna:\n",
    "    - Lista de líneas del reporte como strings.\n",
    "    \"\"\"\n",
    "    if saveToFile:\n",
    "        os.makedirs(reports, exist_ok=True)\n",
    "\n",
    "    num_filas, num_columnas = df.shape\n",
    "    duplicados_filas = df.duplicated().sum()\n",
    "    nulos_por_columna = df.isnull().sum()\n",
    "    tipos_datos = df.dtypes\n",
    "\n",
    "    # Armar el contenido del reporte\n",
    "    reporte = []\n",
    "    reporte.append(f\"Total de filas: {num_filas}\")\n",
    "    reporte.append(f\"Total de columnas: {num_columnas}\")\n",
    "    reporte.append(f\"Filas duplicadas: {duplicados_filas}\")\n",
    "    reporte.append(\"\\nValores nulos por columna:\")\n",
    "    reporte.extend([f\"{col}: {nulos}\" for col, nulos in nulos_por_columna.items()])\n",
    "    reporte.append(\"\\nTipos de datos por columna:\")\n",
    "    reporte.extend([f\"{col}: {tipo}\" for col, tipo in tipos_datos.items()])\n",
    "\n",
    "    if saveToFile:\n",
    "        with open(os.path.join(reports, \"reporte_general.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(\"\\n\".join(reporte))\n",
    "        print(\"Reporte generado en 'reportes/reporte_general.txt'\")\n",
    "\n",
    "    return reporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e2e924",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_generate_report = True\n",
    "report_lines = generateDataReport(df, saveToFile=is_generate_report)\n",
    "# print(\"\\n\".join(report_lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7e2aee",
   "metadata": {},
   "source": [
    "## Análisis Exploratorio Inicial\n",
    "\n",
    "En esta etapa se realizará un análisis exploratorio más profundo del conjunto de datos crudo, con el objetivo de entender mejor su contenido, diversidad y consistencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2404ffe1-d7f5-45e0-8b11-d783e34dc9e7",
   "metadata": {},
   "source": [
    "## Descripción de los Datos\n",
    "Se describen los datos y las transformaciones necesarias que se les realizaran a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d606e94-d7a3-473a-8627-a503dc52d91a",
   "metadata": {},
   "source": [
    "## Limpieza de los datos\n",
    "Se procede a ejecutar las transformaciones previamente ideadas y a unificar todos los datasets en uno solo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c1b5c3",
   "metadata": {},
   "source": [
    "### Sección 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07572489",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd40e286",
   "metadata": {},
   "source": [
    "### Sección 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8695c97-2e51-4196-96f7-bbe866501762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
