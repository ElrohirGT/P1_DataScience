{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d15c3f4-e6da-4c52-8e25-33f536d6087c",
   "metadata": {},
   "source": [
    "# Proyecto 1\n",
    "* Flavio Galán 22386\n",
    "* Josue Say\n",
    "* Isabella Miralles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4322479-0609-4733-9ce1-979917dbfc86",
   "metadata": {},
   "source": [
    "## Descarga de los Datos\n",
    "Para descargar los datos se utiliza Selenium y Python, además se tiene un sistema de cacheo que funciona en base al archivo `links_cache.txt`. Si este archivo ya existe entonces no se realizará ninguna descarga de los datos. Los datos se guardan en varios archivos txt. Cada uno representa la columna del dataframe y todos los datos de esa columna. No se tienen en un formato JSON ni CSV sino que se guardan directamente en formato python para la facilidad de extracción usando el mismo lenguaje. Ya que estos son los datos sucios no hay ningún problema con guardarlos así, los datos limpios ya se guardarán en un formaton más estandarizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e95a071-af81-4d6c-8a94-160f46a335bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "cache_file_name = \"links_cache.txt\"\n",
    "zip_dir = \"zips/\"\n",
    "files_dir = \"data/\"\n",
    "\n",
    "codigo = []\n",
    "distrito = []\n",
    "departamento = []\n",
    "municipio = []\n",
    "establecimiento = []\n",
    "direccion = []\n",
    "telefono = []\n",
    "supervisor = []\n",
    "director = []\n",
    "nivel = []\n",
    "sector = []\n",
    "area = []\n",
    "status = []\n",
    "modalidad = []\n",
    "jornada = []\n",
    "plan = []\n",
    "departamental = []\n",
    "agggrArrays = [\n",
    "    codigo,\n",
    "    distrito,\n",
    "    departamento,\n",
    "    municipio,\n",
    "    establecimiento,\n",
    "    direccion,\n",
    "    telefono,\n",
    "    supervisor,\n",
    "    director,\n",
    "    nivel,\n",
    "    sector,\n",
    "    area,\n",
    "    status,\n",
    "    modalidad,\n",
    "    jornada,\n",
    "    plan,\n",
    "    departamental,\n",
    "]\n",
    "filenames = [\n",
    "    \"codigo\",\n",
    "    \"distrito\",\n",
    "    \"departamento\",\n",
    "    \"municipio\",\n",
    "    \"establecimiento\",\n",
    "    \"direccion\",\n",
    "    \"telefono\",\n",
    "    \"supervisor\",\n",
    "    \"director\",\n",
    "    \"nivel\",\n",
    "    \"sector\",\n",
    "    \"area\",\n",
    "    \"status\",\n",
    "    \"modalidad\",\n",
    "    \"jornada\",\n",
    "    \"plan\",\n",
    "    \"departamental\",\n",
    "]\n",
    "\n",
    "if os.path.exists(cache_file_name):\n",
    "    for idx in range(len(filenames)):\n",
    "        filename = filenames[idx]\n",
    "        data = agggrArrays[idx]\n",
    "        with open(zip_dir + filename + \".txt\", \"r\") as file:\n",
    "            content = file.read()\n",
    "            data = eval(content)\n",
    "else:\n",
    "    with webdriver.Firefox() as driver:\n",
    "        driver.implicitly_wait(3)\n",
    "\n",
    "        driver.get(\"http://www.mineduc.gob.gt/BUSCAESTABLECIMIENTO_GE/\")\n",
    "        assert \"Búsqueda de centros\" in driver.title\n",
    "\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located(\n",
    "                (By.XPATH, \"//*[@id='_ctl0_ContentPlaceHolder1_cmbDepartamento']\")\n",
    "            )\n",
    "        )\n",
    "        deptSelect = driver.find_element(\n",
    "            By.XPATH, \"//*[@id='_ctl0_ContentPlaceHolder1_cmbDepartamento']\"\n",
    "        )\n",
    "        deptSelect = Select(deptSelect)\n",
    "        depts = deptSelect.options\n",
    "        print(\"Getting depts\")\n",
    "        for idx in range(len(depts) - 1):\n",
    "            print(\"Selecting dept\", idx + 1)\n",
    "            deptSelect = driver.find_element(\n",
    "                By.XPATH, \"//*[@id='_ctl0_ContentPlaceHolder1_cmbDepartamento']\"\n",
    "            )\n",
    "            deptSelect = Select(deptSelect)\n",
    "            deptSelect.select_by_index(idx + 1)\n",
    "            print(\"Finding education level\")\n",
    "            levelSelect = driver.find_element(\n",
    "                By.XPATH, '//*[@id=\"_ctl0_ContentPlaceHolder1_cmbNivel\"]'\n",
    "            )\n",
    "            levelSelect = Select(levelSelect)\n",
    "            print(\"Selecting diversificado\")\n",
    "            levelSelect.select_by_value(\"46\")  # 46 es Diversificado\n",
    "            print(\"Finding search button\")\n",
    "            btn = driver.find_element(\n",
    "                By.XPATH, \"//*[@id='_ctl0_ContentPlaceHolder1_IbtnConsultar']\"\n",
    "            )\n",
    "            btn.click()\n",
    "            print(\"Clicking button\")\n",
    "\n",
    "            # Wait for results\n",
    "            print(\"Esperando por resultados\")\n",
    "            time.sleep(5)\n",
    "            print(\"Asumimos que se obtuvieron los resultados\")\n",
    "\n",
    "            table = driver.find_element(\n",
    "                By.XPATH, \"//*[@id='_ctl0_ContentPlaceHolder1_dgResultado']\"\n",
    "            )\n",
    "            rows = table.find_elements(By.XPATH, \".//tr\")\n",
    "            for rowIdx in range(\n",
    "                1, len(rows) - 1\n",
    "            ):  # La última fila siempre es una vacía\n",
    "                cells = rows[rowIdx].find_elements(By.XPATH, \".//td\")\n",
    "\n",
    "                for cellIdx in range(1, len(cells)):\n",
    "                    agggrArrays[cellIdx - 1].append(\n",
    "                        cells[cellIdx].get_attribute(\"textContent\")\n",
    "                    )\n",
    "\n",
    "            # print(\"Obtained following names\")\n",
    "            # print(establecimiento)\n",
    "            # exit(1)\n",
    "\n",
    "        print(\"Saving cache...\")\n",
    "        subprocess.run([\"mkdir\", \"-p\", zip_dir])\n",
    "        for idx in range(len(filenames)):\n",
    "            filename = filenames[idx]\n",
    "            data = agggrArrays[idx]\n",
    "\n",
    "            lines = [\"[\"]\n",
    "            for val in data:\n",
    "                line = f\"\\t'''{val}''',\\n\"\n",
    "                lines.append(line)\n",
    "            lines.append(\"]\")\n",
    "\n",
    "            with open(zip_dir + filename + \".txt\", \"w\") as file:\n",
    "                file.writelines(lines)\n",
    "\n",
    "        with open(cache_file_name, \"w\") as file:\n",
    "            file.write(\"DELETE ME IF YOU WANT TO REDOWNLOAD DATA!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19e80ca-c57f-4c84-b121-62c2acfdfa17",
   "metadata": {},
   "source": [
    "Si ya se tienen los datos descargados pero se necesita generar el dataframe entonces corre el siguiente script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08c839c-a0e3-498e-9c62-457aed3d1bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {colName: colData for (colName, colData) in zip(filenames, agggrArrays)}\n",
    ")\n",
    "print(\"The resulting Dataframe is\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2404ffe1-d7f5-45e0-8b11-d783e34dc9e7",
   "metadata": {},
   "source": [
    "## Descripción de los Datos\n",
    "Se describen los datos y las transformaciones necesarias que se les realizaran a continuación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d606e94-d7a3-473a-8627-a503dc52d91a",
   "metadata": {},
   "source": [
    "## Limpieza de los datos\n",
    "Se procede a ejecutar las transformaciones previamente ideadas y a unificar todos los datasets en uno solo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8695c97-2e51-4196-96f7-bbe866501762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
